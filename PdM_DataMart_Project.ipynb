{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **Predictive Maintenance Datamart Notebook**\n",
                "\n",
                "**üìù Dataset Overview:**  \n",
                "\n",
                "These datasets supports the analysis of machine performance and predictiive maintenance by integrating sensor telemetry, error logs, maintenance actions, and failure events. The analysis can help predict failures, optimize maintenance schedules and reduce machine downtime.\n",
                "\n",
                "**üìù Data Source:**  \n",
                "\n",
                "The source datasets include:\n",
                "\n",
                "| Source Table      | Description                                                                                          |\n",
                "|-------------------|------------------------------------------------------------------------------------------------------|\n",
                "| `PdM_errors`      | Contains error logs with timestamps and machine IDs.                                                 |\n",
                "| `PdM_failures`    | Tracks machine failures with timestamps and failure types.                                           |\n",
                "| `PdM_machines`    | Details about the machines, such as ID, age, and type.                                               |\n",
                "| `PdM_maint`       | Maintenance records including timestamps and activity types.                                         |\n",
                "| `PdM_telemetry`   | Time-series data with sensor readings for each machine, such as voltage, rotation, pressure, and vibration. |  \n",
                "\n",
                "\n",
                "\n",
                "The datasets are sourced from Microsoft Azure Predictive Maintenance Dataset. It can be found on [Kaggle](https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance/data).  \n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "91384faa-e82f-4d80-b1e4-f6d0eb8b26c7"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üñ•Ô∏è¬†**Create Schemas and Tables using DDL**\n",
                "\n",
                "\n",
                "### **üìç1. Schema Creation**\n",
                "\n",
                "In this project, schemas are being created to logically separate and manage data at different stages of the data processing lifecycle. Each schema serves a specific purpose to ensure data integrity, performance, and maintainability. SQL scripts will be used to define the schema and tables using DDL (Data Definition Language).  \n",
                "\n",
                "The following schemas were created:\n",
                "\n",
                "| Schema            | Description                                                                                       |\n",
                "|--------------------|---------------------------------------------------------------------------------------------------|\n",
                "| `stg` (staging)  | Acts as a temporary area to store raw data before transformation.                            |\n",
                "| `dim` (dimension)| Stores descriptive or reference data used for categorization and filtering.                 |\n",
                "| `f` (fact)       | Centralizes quantitative data like failure counts, error counts, and average telemetry readings. |\n",
                "¬†\n",
                "\n",
                "The following is performed in T-SQL against an instance of MS SQL Server 2022 to create the schemas to be used in this project (stg, dim and f): \n",
                "\n",
                "```\n",
                "-- Creating Dimension Schema\n",
                "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dim' ) \n",
                "BEGIN\n",
                "\tEXEC sp_executesql N'CREATE SCHEMA dim AUTHORIZATION dbo;'\n",
                "END\n",
                ";\n",
                "\n",
                "GO\n",
                "-- Creating Staging Schema\n",
                "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'stg' ) \n",
                "BEGIN\n",
                "\tEXEC sp_executesql N'CREATE SCHEMA stg AUTHORIZATION dbo;'\n",
                "END\n",
                ";\n",
                "\n",
                "GO\n",
                "-- Creating Fact Schema\n",
                "IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'f' ) \n",
                "BEGIN\n",
                "\tEXEC sp_executesql N'CREATE SCHEMA f AUTHORIZATION dbo;'\n",
                "END\n",
                ";\n",
                "\n",
                "GO\n",
                "\n",
                "```  \n",
                "\n",
                "By using `IF NOT EXISTS`, each schema is created only if it does not already exist in the database."
            ],
            "metadata": {
                "azdata_cell_guid": "e847e8cb-cb3d-4f26-bf06-33930acf1ac5"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The datamart will be constructed as the following **Entity Relationship Diagram**:\n",
                "\n",
                " ![Entity Relationship Diagram](./images/PdM_ERD.png)    \n",
                "\n",
                "\n",
                " Each machine in `dim.Machines` can have multiple records in `dim.Errors`, `dim.Failures`, `dim.Maintenance`, and `f.Telemetry`. So that relationship is one to many.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "77048387-2e25-4bcf-a5c9-43af622c8f1f"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **üìç2. Dimension tables creation**\n",
                "\n",
                "The following dimension tables were created to organize and structure the supporting data:  \n",
                "\n",
                "| Dimension Table     | Description                                                                          |\n",
                "|---------------------|--------------------------------------------------------------------------------------|\n",
                "| `dim.Machines`      | Machine details like Machine ID, model, and age.                                    |\n",
                "| `dim.Errors`        | Logs machine errors.                                                                |\n",
                "| `dim.Failures`      | Logs machine failures.                                                              |\n",
                "| `dim.Maintenance`   | Tracks maintenance history for machine components.                                  |\n",
                "| `dim.Calendar`      | Time dimension for analysis, including date, month, and year.                       |\n",
                "\n",
                "The SQL scripts for the dimension tables were created with the appropraite data types and keys.\n",
                "\n",
                "For example the `dim.machines` table was created using the following script:\n",
                "\n",
                "```\n",
                "IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'dim' AND TABLE_NAME = 'Machines')\n",
                "BEGIN\n",
                "    CREATE TABLE dim.Machines (\n",
                "        pkMachineID INT IDENTITY(1,1) NOT NULL,\n",
                "        MachineID INT NOT NULL,\n",
                "        Model NVARCHAR(10) NOT NULL,\n",
                "        Age INT NOT NULL\n",
                "    );\n",
                "\n",
                "    ALTER TABLE dim.Machines\n",
                "    ADD CONSTRAINT PK_Machines PRIMARY KEY (pkMachineID);\n",
                "\n",
                "    ALTER TABLE dim.Machines\n",
                "    ADD CONSTRAINT UC_Machines UNIQUE (MachineID);\n",
                "END;\n",
                "GO\n",
                "\n",
                "```   \n",
                "\n",
                "This script ensures that `dim.Machines` has a primary key (pkMachineID), while also maintaining a unique constraint on MachineID to prevent duplicate machine entries. Additionally, all data types were chosen based on the dataset structure to match the expected data (e.g. INT for IDs and NVARCHAR for text fields).\n",
                "\n",
                "This was repeated for the other dimension tables with their respective column names.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "e6d78e69-c834-4398-8fbc-418e24789e4f"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **üìç3. Fact table creation**\n",
                "\n",
                "\n",
                "The telemetry becomes a fact table, as it stores measurable events linked to dimensions like machines and time. It can be linked telemetry data to failures, errors, or maintenance events to identify patterns.\n",
                "\n",
                "| Fact Table    | Description                                                   |\n",
                "|---------------|---------------------------------------------------------------|\n",
                "| `f.Telemetry` | Stores telemetry data (performance metrics) for machines.     |\n",
                "  \n",
                "\n",
                "For `f.Telemetry`, the table was created with this script:\n",
                "\n",
                "```\n",
                "IF NOT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'f' AND TABLE_NAME = 'Telemetry')\n",
                "BEGIN\n",
                "    CREATE TABLE f.Telemetry (\n",
                "        TelemetryID INT IDENTITY(1,1) NOT NULL,\n",
                "        MachineID INT NOT NULL,\n",
                "        SensorReadTime DATETIME NOT NULL,\n",
                "        Volt FLOAT NOT NULL,\n",
                "        Rotate FLOAT NOT NULL,\n",
                "        Pressure FLOAT NOT NULL,\n",
                "        Vibration FLOAT NOT NULL\n",
                "    );\n",
                "\n",
                "    ALTER TABLE f.Telemetry\n",
                "    ADD CONSTRAINT PK_Telemetry PRIMARY KEY (TelemetryID);\n",
                "\n",
                "    ALTER TABLE f.Telemetry\n",
                "    ADD CONSTRAINT FK_Telemetry_MachineID FOREIGN KEY (MachineID)\n",
                "    REFERENCES dim.Machines (MachineID);\n",
                "\n",
                "    ALTER TABLE f.Telemetry\n",
                "    ADD CONSTRAINT FK_Telemetry_Datetime FOREIGN KEY (datetime)\n",
                "    REFERENCES dim.Calendar (datetime);\n",
                "END;\n",
                "GO\n",
                "\n",
                "```  \n",
                "\n",
                "The primary key `TelemetryID` uniquely identifies each record. Foreign Keys, `MachineID` links to `dim.Machines` and `SensorReadTime` to `dim.Calendar` for machine and time-based analysis.\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "f4745fe5-7d09-4300-86bc-1199d87600c6"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The full SQL DDL scripts for the datamart creation can be found¬†[here](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\SQL_files\\PdM_Sql_DDL.sql)."
            ],
            "metadata": {
                "azdata_cell_guid": "16dc0b49-84a5-4fc9-8c15-fc5ae931f475"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üñ•Ô∏è¬†**Load data into tables using DML**\n",
                "\n",
                "\n",
                "### **üìç1. Load data into staging tables**\n",
                "Data for staging tables was imported using the [SQL Server Import and Export Wizard](https://github.com/w0435723/PdM_DataMart_Project/blob/main/images/import%2520wizard.png) .The source data files were in CSV format, and each file was mapped to the corresponding staging table under the 'stg' schema. Column mappings and data types were verified during the import process to ensure compatibility with the existing table schema. The import operation used the \"Append Rows\" option to add data to existing staging tables without overwriting or truncating any previous data.   \n",
                "\n",
                "\n",
                "### **üìç2. Loading Dimension tables**\n",
                "\n",
                "Dimension tables were populated from staging after verifying that data has been transformed and has no errors.\n",
                "\n",
                "For `dim.Machines`:\n",
                "\n",
                "```\n",
                "INSERT INTO dim.Machines (MachineID, Model, Age)\n",
                "SELECT \n",
                "    s_m.MachineID,\n",
                "    s_m.Model,\n",
                "    s_m.Age\n",
                "FROM stg.Machines AS s_m\n",
                "WHERE s_m.MachineID NOT IN (SELECT MachineID FROM dim.Machines);\n",
                "GO\n",
                "\n",
                "```  \n",
                "\n",
                "This was repeated for the other dimension tables.\n",
                "\n",
                "### **üìç3. Loading fact table**\n",
                "\n",
                "Raw data was loaded into the fact table first without aggregation. Aggregated views or summary tables will be created separately so that flexibility is not limited.  \n",
                "\n",
                "For `f.telemetry`:  \n",
                "\n",
                "```\n",
                "INSERT INTO f.Telemetry (MachineID, SensorReadTime, Volt, Rotate, Pressure, Vibration)\n",
                "SELECT \n",
                "    s_t.MachineID,\n",
                "    s_t.SensorReadTime,\n",
                "    s_t.Volt,\n",
                "    s_t.Rotate,\n",
                "    s_t.Pressure,\n",
                "    s_t.Vibration\n",
                "FROM stg.Telemetry AS s_t\n",
                "WHERE NOT EXISTS (\n",
                "    SELECT 1 \n",
                "    FROM f.Telemetry AS f_t\n",
                "    WHERE s_t.MachineID = f_t.MachineID\n",
                "      AND s_t.SensorReadTime = f_t.SensorReadTime\n",
                ");\n",
                "GO\n",
                "\n",
                "```  \n",
                "\n",
                "A test database, called Sandbox, was created to run the SQL scripts and ensure it is runable to load data into the datamart.  \n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "0d3cbdb4-91d4-4abe-90da-1cdfd5009837"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "The full SQL DML scripts for loading datamart creation can be found¬†[here](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\SQL_files\\PdM_Sql_DML.sql)."
            ],
            "metadata": {
                "azdata_cell_guid": "d052f37d-086c-44fb-8842-df860e47d69e"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "**üìù Summary:**\n",
                "\n",
                "Quick navigation to all other project files can be found at these links:¬†¬†\n",
                "\n",
                "- [Readme](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\README.md)¬†\n",
                "- [ERD diagram](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\images\\PdM_ERD.png)¬†¬†\n",
                "- [SQL DDL Scripts](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\SQL_files\\PdM_Sql_DDL.sql)¬† ¬†\n",
                "- [SQL DML Loader](https:\\github.com\\w0435723\\PdM_DataMart_Project\\blob\\main\\SQL_files\\PdM_Sql_DML.sql)¬†¬†\n",
                "\n",
                "- [Source data files](https:\\github.com\\w0435723\\PdM_DataMart_Project\\tree\\main\\data)  \n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "efa88b59-2948-4579-a341-5861d8fcaf65"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "**üìù References:**\n",
                "\n",
                "_All emojis in this notebook are sourced from¬†[emojicopy](https:\\emojicopy.com\\)._\n",
                "\n",
                "_The datamart was created based on the principles of Star Schema Design as outlined by¬†[Ralph Kimball](https:\\www.kimballgroup.com\\data-warehouse-business-intelligence-resources\\kimball-techniques\\dimensional-modeling-techniques\\)._  \n",
                "\n",
                "The source datasets are sourced from Microsoft Azure Predictive Maintenance Dataset on [Kaggle](https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance/data)."
            ],
            "metadata": {
                "azdata_cell_guid": "2b44ff3c-8b23-4506-af19-75c8b91151fc"
            },
            "attachments": {}
        }
    ]
}